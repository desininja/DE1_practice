{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Structured APIs').master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from the csv file and infering the schema\n",
    "df = spark.read.load(\"users.csv\", format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|       job|\n",
      "+-------+---+----------+\n",
      "| Vishwa| 61|  Engineer|\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Rishavv| 21|   Student|\n",
      "|Shivani| 69|Consultant|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Rohit| 31|   Captain|\n",
      "|  Virat| 32|   Blogger|\n",
      "| Akshay| 45|     Actor|\n",
      "|Amitabh| 70| Superstar|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the elements of the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the schema instead of inferring it \n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType, LongType\n",
    "\n",
    "fileSchema = StructType([StructField('name', StringType(),True),\n",
    "                        StructField('age', LongType(),True),\n",
    "                        StructField('job_title', StringType(),True)])\n",
    "\n",
    "df2 = spark.read.load(\"users.csv\", format=\"csv\", sep=\",\", schema = fileSchema, header=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age| job_title|\n",
      "+-------+---+----------+\n",
      "| Vishwa| 61|  Engineer|\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Rishavv| 21|   Student|\n",
      "|Shivani| 69|Consultant|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Rohit| 31|   Captain|\n",
      "|  Virat| 32|   Blogger|\n",
      "| Akshay| 45|     Actor|\n",
      "|Amitabh| 70| Superstar|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing this dataframe in parquet\n",
    "df.write.parquet(\"users_2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing this dataframe in json format\n",
    "df.write.json(\"users_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing this dataframe in orc format\n",
    "df.write.orc(\"users_2.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from the JSON file and infering the schema\n",
    "df=spark.read.json(\"users_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+\n",
      "|age|       job|   name|\n",
      "+---+----------+-------+\n",
      "| 61|  Engineer| Vishwa|\n",
      "| 79|    Doctor|  Mohan|\n",
      "| 21|   Student|Rishavv|\n",
      "| 69|Consultant|Shivani|\n",
      "| 35| Cricketer| Sachin|\n",
      "| 31|   Captain|  Rohit|\n",
      "| 32|   Blogger|  Virat|\n",
      "| 45|     Actor| Akshay|\n",
      "| 70| Superstar|Amitabh|\n",
      "+---+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the schema in the case of json\n",
    "fileSchema = StructType([StructField('name', StringType(),True),\n",
    "                        StructField('age', IntegerType(),True),\n",
    "                        StructField('job', StringType(),True)])\n",
    "\n",
    "df2 = spark.read.json(\"users_2.json\", schema = fileSchema) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|       job|\n",
      "+-------+---+----------+\n",
      "| Vishwa| 61|  Engineer|\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Rishavv| 21|   Student|\n",
      "|Shivani| 69|Consultant|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Rohit| 31|   Captain|\n",
      "|  Virat| 32|   Blogger|\n",
      "| Akshay| 45|     Actor|\n",
      "|Amitabh| 70| Superstar|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from the parquet file\n",
    "df = spark.read.parquet(\"users_2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|       job|\n",
      "+-------+---+----------+\n",
      "| Vishwa| 61|  Engineer|\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Rishavv| 21|   Student|\n",
      "|Shivani| 69|Consultant|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Rohit| 31|   Captain|\n",
      "|  Virat| 32|   Blogger|\n",
      "| Akshay| 45|     Actor|\n",
      "|Amitabh| 70| Superstar|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from the orc file\n",
    "df = spark.read.orc(\"users_2.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|       job|\n",
      "+-------+---+----------+\n",
      "| Vishwa| 61|  Engineer|\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Rishavv| 21|   Student|\n",
      "|Shivani| 69|Consultant|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Rohit| 31|   Captain|\n",
      "|  Virat| 32|   Blogger|\n",
      "| Akshay| 45|     Actor|\n",
      "|Amitabh| 70| Superstar|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4d5deee12485ea1fbdc6cd4b5f389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1110, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas==0.25.1\")\n",
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "#spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the pandas dataframe\n",
    "pdf = pd.DataFrame(np.random.rand(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0  0.137790  0.922133  0.123957\n",
      "1  0.333376  0.580820  0.537393\n",
      "2  0.904449  0.810433  0.479234\n",
      "3  0.953199  0.540097  0.837223\n",
      "4  0.828297  0.403286  0.961653\n",
      "5  0.158290  0.019993  0.851900\n",
      "6  0.530120  0.729136  0.445259\n",
      "7  0.390467  0.405339  0.525516\n",
      "8  0.247529  0.782043  0.519066\n",
      "9  0.896800  0.852220  0.395960\n"
     ]
    }
   ],
   "source": [
    "print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Data frames from the Pandas df\n",
    "#!pip install pyarrow\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: double (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+-------------------+\n",
      "|                  0|                  1|                  2|\n",
      "+-------------------+-------------------+-------------------+\n",
      "| 0.1377895978491671| 0.9221329979374493|0.12395744510215878|\n",
      "| 0.3333761883592037|   0.58081961105366| 0.5373933805243502|\n",
      "| 0.9044492722416171| 0.8104334656033485| 0.4792336229672418|\n",
      "| 0.9531987807211716| 0.5400969836419792| 0.8372231053420505|\n",
      "| 0.8282967967547646|0.40328575729156513| 0.9616529099359863|\n",
      "|0.15829049487080626|0.01999262568693161| 0.8518999625814911|\n",
      "| 0.5301195926072625| 0.7291359184343568|0.44525864523163383|\n",
      "|0.39046747599154874| 0.4053385070658696| 0.5255157570818327|\n",
      "|0.24752913927709286| 0.7820433310400476|  0.519066410203265|\n",
      "| 0.8968000042943823|   0.85222036664126| 0.3959601229881846|\n",
      "+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0  0.137790  0.922133  0.123957\n",
      "1  0.333376  0.580820  0.537393\n",
      "2  0.904449  0.810433  0.479234\n",
      "3  0.953199  0.540097  0.837223\n",
      "4  0.828297  0.403286  0.961653\n",
      "5  0.158290  0.019993  0.851900\n",
      "6  0.530120  0.729136  0.445259\n",
      "7  0.390467  0.405339  0.525516\n",
      "8  0.247529  0.782043  0.519066\n",
      "9  0.896800  0.852220  0.395960\n"
     ]
    }
   ],
   "source": [
    "result_pdf = df.select(\"*\").toPandas()\n",
    "print(result_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######. operations on data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|       job|\n",
      "+-------+---+----------+\n",
      "| Vishwa| 61|  Engineer|\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Rishavv| 21|   Student|\n",
      "|Shivani| 69|Consultant|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Rohit| 31|   Captain|\n",
      "|  Virat| 32|   Blogger|\n",
      "| Akshay| 45|     Actor|\n",
      "|Amitabh| 70| Superstar|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Select all columns in dataframe\n",
    "df = spark.read.orc(\"users_2.orc\")\n",
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "| Vishwa|\n",
      "|  Mohan|\n",
      "|Rishavv|\n",
      "|Shivani|\n",
      "| Sachin|\n",
      "|  Rohit|\n",
      "|  Virat|\n",
      "| Akshay|\n",
      "|Amitabh|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Selecting specific column in dataframe\n",
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Vishwa', age=61, job='Engineer'),\n",
       " Row(name='Mohan', age=79, job='Doctor'),\n",
       " Row(name='Shivani', age=69, job='Consultant'),\n",
       " Row(name='Amitabh', age=70, job='Superstar')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter operations\n",
    "df.filter(df['age']>50).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 31|    1|\n",
      "| 61|    1|\n",
      "| 35|    1|\n",
      "| 69|    1|\n",
      "| 45|    1|\n",
      "| 70|    1|\n",
      "| 21|    1|\n",
      "| 32|    1|\n",
      "| 79|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by\n",
    "df.groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|       job|\n",
      "+-------+---+----------+\n",
      "|  Mohan| 79|    Doctor|\n",
      "|Amitabh| 70| Superstar|\n",
      "|Shivani| 69|Consultant|\n",
      "| Vishwa| 61|  Engineer|\n",
      "| Akshay| 45|     Actor|\n",
      "| Sachin| 35| Cricketer|\n",
      "|  Virat| 32|   Blogger|\n",
      "|  Rohit| 31|   Captain|\n",
      "|Rishavv| 21|   Student|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Order by\n",
    "df.orderBy(df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################  Spark SQL   ##########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
